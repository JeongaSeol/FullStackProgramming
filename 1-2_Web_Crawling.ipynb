{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104e0e70",
   "metadata": {},
   "source": [
    "# 1-2 Web Crawling\n",
    "\n",
    "## 1. HTML 소스코드 분석하고 처리하기\n",
    "\n",
    "### 1) 줄 바꿈으로 가독성 높이기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f2c6f8",
   "metadata": {},
   "source": [
    "#### * HTML 소스코드를 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99eda4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing C:/Web_Crawling/br_example_constitution.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:/Web_Crawling/br_example_constitution.html\n",
    "<!doctype html>\n",
    "<html>\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>줄 바꿈 테스트 예제</title>\n",
    "  </head>\n",
    "  <body>\n",
    "  <p id=\"title\"><b>대한민국헌법</b></p>\n",
    "  <p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>\n",
    "  <p id=\"content\">제2조 <br/>①대한민국의 국민이 되는 요건은 법률로 정한다.<br/>②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다.</p>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498305df",
   "metadata": {},
   "source": [
    "#### * HTML 파일을 읽어서 변수 html_source에 할당한 후 요소에서 텍스트 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746a0ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법\n",
      "제1조 ①대한민국은 민주공화국이다.②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.\n",
      "제2조 ①대한민국의 국민이 되는 요건은 법률로 정한다.②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "f = open('C:/Web_Crawling/br_example_constitution.html', encoding = 'utf-8')\n",
    "\n",
    "html_source = f.read()\n",
    "f.close()\n",
    "\n",
    "soup = BeautifulSoup(html_source, 'lxml')\n",
    "\n",
    "title = soup.find('p', {'id':'title'})\n",
    "contents = soup.find_all('p', {'id':'content'})\n",
    "\n",
    "print(title.get_text())\n",
    "for content in contents :\n",
    "    print(content.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0059670",
   "metadata": {},
   "source": [
    "#### * 추출된 HTML 코드에서 줄 바꿈 태그를 파이썬의 개행문자(\\n)으로 바꿈\n",
    "#### * Beautiful Soup의 `replace_with(새로운 문자열)`을 이용\n",
    "#### * 기존의 태그나 문자열을 새로운 태그나 문자열로 바꿈\n",
    "#### * `find_result = BeautifulSoup.find('태그')`\n",
    "#### * `find_result.replace_with('새 태그나 문자열')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfc1ec",
   "metadata": {},
   "source": [
    "#### * HTML 코드에서 br 태그를 파이썬의 개행 문자로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc9cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 태그 p로 찾은 요소\n",
      "<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>\n",
      "--> 결과에서 태그 br로 찾은 요소: <br/>\n",
      "--> 태그 br을 개행문자로 바꾼 결과\n",
      "<p id=\"content\">제1조 \n",
      "①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>\n"
     ]
    }
   ],
   "source": [
    "html1 = '<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>'\n",
    "\n",
    "soup1 = BeautifulSoup(html1,'lxml')\n",
    "\n",
    "print(\"--> 태그 p로 찾은 요소\")\n",
    "content1 = soup1.find('p',{'id':'content'})\n",
    "print(content1)\n",
    "\n",
    "br_content = content1.find('br')\n",
    "print('--> 결과에서 태그 br로 찾은 요소:', br_content)\n",
    "\n",
    "br_content.replace_with('\\n')\n",
    "print('--> 태그 br을 개행문자로 바꾼 결과')\n",
    "print(content1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9accbc5f",
   "metadata": {},
   "source": [
    "### 2) 추출된 요소에 전체 적용\n",
    "\n",
    "#### * HTML 코드에서 br 태그를 파이썬의 개행문자로 전체 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0afdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"content\">제1조 \n",
      "①대한민국은 민주공화국이다.\n",
      "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>\n"
     ]
    }
   ],
   "source": [
    "soup2 = BeautifulSoup(html1, 'lxml')\n",
    "content2 = soup2.find('p',{'id':'content'})\n",
    "\n",
    "br_contents = content2.find_all('br')\n",
    "for br_content in br_contents:\n",
    "    br_content.replace_with('\\n')\n",
    "print(content2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37373bad",
   "metadata": {},
   "source": [
    "#### * 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283694d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_newline(soup_html):\n",
    "    br_to_newlines = soup_html.find_all('br')\n",
    "    for br_to_newline in br_to_newlines:\n",
    "        br_to_newline.replace_with('\\n')\n",
    "    return soup_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322dbb22",
   "metadata": {},
   "source": [
    "#### * Beautiful Soup으로 파싱된 HTML 소스에서 br 태그를 개행문자`\\n`으로 변경\n",
    "#### * 함수를 이용한 결과에서 요소의 내용만 추출하기 위해 `get_text()` 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ad55e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제1조 \n",
      "①대한민국은 민주공화국이다.\n",
      "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.\n"
     ]
    }
   ],
   "source": [
    "soup2 = BeautifulSoup(html1, 'lxml')\n",
    "content2 = soup2.find('p',{'id':'content'})\n",
    "content3 = replace_newline(content2)\n",
    "print(content3.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4fb71a",
   "metadata": {},
   "source": [
    "#### * HTML 소스코드를 할당한 변수 html_source에 최종적으로 위의 코드를 적용\n",
    "\n",
    "#### - 줄을 바꾸어 문단을 구분하는 p 태그를 표기하기 위해서 get_text()를 출력할때 `\\n` 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8426aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법 \n",
      "\n",
      "제1조 \n",
      "①대한민국은 민주공화국이다.\n",
      "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다. \n",
      "\n",
      "제2조 \n",
      "①대한민국의 국민이 되는 요건은 법률로 정한다.\n",
      "②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_source, 'lxml')\n",
    "\n",
    "title = soup.find('p',{'id':'title'})\n",
    "contents = soup.find_all('p',{'id':'content'})\n",
    "\n",
    "print(title.get_text(), '\\n')\n",
    "\n",
    "for content in contents:\n",
    "    content1 = replace_newline(content)\n",
    "    print(content1.get_text(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08d4d1",
   "metadata": {},
   "source": [
    "## 2. 웹 사이트에서 데이터 가져오기\n",
    "\n",
    "### \n",
    "\n",
    "### 1) 웹 스크래핑(Scraping) 시 주의사항\n",
    "\n",
    "#### * 해당 웹 사이트에 너무 빈번하게 접근 금지\n",
    "#### * 사이트는 언제든지 예고 없이 변경 될 수 있음\n",
    "#### * 인터넷 상에 공개된 데이터라도 저작권(copyright)이 있는 경우가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e502b",
   "metadata": {},
   "source": [
    "### 2) 순위 데이터 가져오기 \n",
    "\n",
    "#### * 사용자들이 방문하는 웹 사이트의 방문 정보(접속수, 페이지 뷰 정보 등) 및 웹 트래픽 분석\n",
    "\n",
    "#### * 선정한 `select()`의 인자 `p a`를 이용해 웹 사이트의 트래픽 순위 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c11f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.alexa.com/topsites/countries/KR'\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, 'lxml')\n",
    "\n",
    "# p태그의 요소 안에서 a태그의 요소를 찾음\n",
    "website_ranking = soup_website_ranking.select('p a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c16a27",
   "metadata": {},
   "source": [
    "#### * 순위 결과가 잘 추출되었는지 변수 website_ranking에 저장된 내용중 일부 출력해서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06dc8c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://support.alexa.com/hc/en-us/articles/200444340\" target=\"_blank\">this explanation</a>,\n",
       " <a href=\"/siteinfo/google.com\">Google.com</a>,\n",
       " <a href=\"/siteinfo/naver.com\">Naver.com</a>,\n",
       " <a href=\"/siteinfo/youtube.com\">Youtube.com</a>,\n",
       " <a href=\"/siteinfo/daum.net\">Daum.net</a>,\n",
       " <a href=\"/siteinfo/tistory.com\">Tistory.com</a>,\n",
       " <a href=\"/siteinfo/kakao.com\">Kakao.com</a>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking[0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10b0b22",
   "metadata": {},
   "source": [
    "#### * 첫 번째 항목을 제외한 리스트 website_ranking[1:]의 각 요소에서 웹 사이트 주소 추출\n",
    "#### * 리스트 모든 항목에 대해 get_text()를 적용하기 위해 리스트 컴프리헨션 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cf3f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_ranking_address = [website_ranking_element.get_text() for website_ranking_element in website_ranking[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49431e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google.com',\n",
       " 'Naver.com',\n",
       " 'Youtube.com',\n",
       " 'Daum.net',\n",
       " 'Tistory.com',\n",
       " 'Kakao.com']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking_address[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b0c1fc",
   "metadata": {},
   "source": [
    "#### * 코드 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bef0db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Top Sites in South Korea]\n",
      "1:Google.com\n",
      "2:Naver.com\n",
      "3:Youtube.com\n",
      "4:Daum.net\n",
      "5:Tistory.com\n",
      "6:Kakao.com\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.alexa.com/topsites/countries/KR'\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, 'lxml')\n",
    "\n",
    "# p태그 중 a태그 요소 추출\n",
    "website_rankig = soup_website_ranking.select('p a')\n",
    "website_ranking_address = [website_ranking_element.get_text() for website_ranking_element in website_ranking[1:]]\n",
    "\n",
    "print('[Top Sites in South Korea]')\n",
    "for k in range(6):\n",
    "    print('{0}:{1}'.format(k+1, website_ranking_address[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8015ef",
   "metadata": {},
   "source": [
    "#### * pandas의 DataFrame을 이용해서 출력 결과의 가독성을 높임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c01f727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naver.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daum.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tistory.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kakao.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Website\n",
       "1   Google.com\n",
       "2    Naver.com\n",
       "3  Youtube.com\n",
       "4     Daum.net\n",
       "5  Tistory.com\n",
       "6    Kakao.com"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "website_ranking_dict = {'Website':website_ranking_address}\n",
    "df = pd.DataFrame(website_ranking_dict, columns=['Website'], index = range(1, len(website_ranking_address)+1))\n",
    "df[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889bfeb9",
   "metadata": {},
   "source": [
    "## 3. 이미지 가져오기\n",
    "\n",
    "###   \n",
    "\n",
    "### 1) 하나의 이미지 내려받기\n",
    "#### * `equests` 라이브러리 이용해서 이미피 파일을 위한 응답 객체 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "265f783c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "html_image = requests.get(url)\n",
    "html_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7819b685",
   "metadata": {},
   "source": [
    "#### * 이미지 주소에서 이미지 파일명만 추출해서 이용\n",
    "#### * 이미지 파일의 전체 경로에서 파일 이름만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a086e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python-logo.png'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_file_name = os.path.basename(url)\n",
    "image_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a80a2",
   "metadata": {},
   "source": [
    "#### * `os.makedirs(folder)`  : folder 경로에 해당 폴더를 생성\n",
    "#### * `os.path.exists(folder)` : folder 경로에 해당 폴더가 존재하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f1df479",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'C:/Web_Crawling/download'\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340c6886",
   "metadata": {},
   "source": [
    "#### * 생성된 폴더와 추출한 이미지 파일명을 합치기 위해 OS 모듈의 메서드 이용\n",
    "#### * `os.path.join(path1[, path2, ...])`\n",
    "#### * `folder` : 파일을 저장하려는 폴더\n",
    "#### * `file` : 파일 이름\n",
    "#### * `os.path.join(folder, file)` : 파일의 전체 경로를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea64001",
   "metadata": {},
   "source": [
    "#### * 생성한 이미지 파일을 위한 폴더와 추출한 이미지 파일을 통합하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86717ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Web_Crawling/download\\\\python-logo.png'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = os.path.join(folder, image_file_name)\n",
    "image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36660f72",
   "metadata": {},
   "source": [
    "#### * 이미지 파일을 저장하기 전에 `open('file_name', 'mode')`을 이용해 파일 오픈\n",
    "#### * `file_name` : 앞에서 지정한 경로 이름\n",
    "#### * `mode` : 쓰기 모드 / 바이너리 모드 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a423e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트가 아닌 이미지 파일이므로 바이너리 파일 모드로 지정\n",
    "imageFile = open(image_path, 'wb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cd8494",
   "metadata": {},
   "source": [
    "#### * requests 라이브러리의 `iter_content(chunk_size)`\n",
    "       - 전체 이미지를 hchunk_size [bytes]만큼 나눠서 내림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3e7c75",
   "metadata": {},
   "source": [
    "#### * 전체 파일의 마지막까지 나눠서 내려 받은 데이터를 차례대로 파일 쓰기를 하면\n",
    "#### 최종적으로 완전한 하나의 이미지 파일을 내려 받기 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f98ea52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터를 1,000,000 바이트씩 나눠서 내려 받고 파일에 순차적으로 저장\n",
    "\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6ed9e",
   "metadata": {},
   "source": [
    "#### * `os.listdir(folder)` : 지정된 폴더의 파일 목록을 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e67efb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python-logo.png']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775518d6",
   "metadata": {},
   "source": [
    "#### * [최종 코드] 이미지 주소를 알 경우 이미지 파일을 내려 받는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2904d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "html_image = requests.get(url)\n",
    "image_file_name = os.path.basename(url)\n",
    "\n",
    "folder = 'C:/Web_Crawling/download'\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "    \n",
    "image_path = os.path.join(folder, image_file_name)\n",
    "\n",
    "imageFile = open(image_path, 'wb')\n",
    "\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e94576f",
   "metadata": {},
   "source": [
    "#### * `select('a img')` : 해당 이미지의 요소가 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c0a6be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"Reshot\" height=\"33\" src=\"https://www.reshot.com/build/reshot-logo--mark-cc49363ac3f7876f854286af4266ead51a7ff9e0fa12f30677c9e758d43dd0d1.svg\" title=\"Reshot\" width=\"46\"/>,\n",
       " <img alt=\"\" class=\"photos-item-card__image\" height=\"2448\" loading=\"lazy\" src=\"https://res.cloudinary.com/twenty20/private_images/t_reshot-400/v1521838685/photosp/bae96789-a5ab-4471-b54f-9686ace09e33/bae96789-a5ab-4471-b54f-9686ace09e33.jpg\" width=\"2448\"/>,\n",
       " <img alt=\"Back off!\" class=\"photos-item-card__image\" height=\"2361\" loading=\"lazy\" src=\"https://res.cloudinary.com/twenty20/private_images/t_reshot-400/v1597098233/photosp/a44357c5-b1c3-41ef-9a65-7a4937b06a44/a44357c5-b1c3-41ef-9a65-7a4937b06a44.jpg\" width=\"3148\"/>,\n",
       " <img alt=\"Orphans\" class=\"photos-item-card__image\" height=\"3375\" loading=\"lazy\" src=\"https://res.cloudinary.com/twenty20/private_images/t_reshot-400/v1617578418/photosp/34fd9c70-8996-4706-a0f1-113231ed3eee/34fd9c70-8996-4706-a0f1-113231ed3eee.jpg\" width=\"3375\"/>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = 'https://reshot.com/search/animal'\n",
    "\n",
    "html_reshot_image = requests.get(URL).text\n",
    "soup_reshot_image = BeautifulSoup(html_reshot_image, 'lxml')\n",
    "reshot_image_elements = soup_reshot_image.select('a img')\n",
    "reshot_image_elements[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a68eff",
   "metadata": {},
   "source": [
    "### 2) 여러 개의 이미지 내려 받기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875f094",
   "metadata": {},
   "source": [
    "#### * 위의 출력 결과에서 img 태그가 포함된 이미지가 있는 요소가 추출된 것을 확인\n",
    "#### * 리스트 reshot_image_elements의 첫 번째 요소 : reshot의 로고 이미지\n",
    "#### * 동물 이미지만 가져오기 위해서는 reshot_image_elements[1:]을 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ae89f",
   "metadata": {},
   "source": [
    "#### * BeautifulSoup에서 `get('속성')` : '속성'에 들어간 '속성값'을 return\n",
    "#### * 추출된 요소에서 `src`의 속성값인 이미지 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed901a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://res.cloudinary.com/twenty20/private_images/t_reshot-400/v1521838685/photosp/bae96789-a5ab-4471-b54f-9686ace09e33/bae96789-a5ab-4471-b54f-9686ace09e33.jpg'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshot_image_url = reshot_image_elements[1].get('src')\n",
    "reshot_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e5ee1",
   "metadata": {},
   "source": [
    "#### * 이미지의 주소를 알고 있을 때 이미지 내려 받는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d81d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_image = requests.get(reshot_image_url)\n",
    "\n",
    "folder = 'C:/Web_Crawling/download'\n",
    "\n",
    "#os.path.basename(URL)은 웹사이트나 폴더가 포함된 파일명에서 파일명만 분리\n",
    "imageFile = open(os.path.join(folder, os.path.basename(reshot_image_url)), 'wb')\n",
    "\n",
    "#이미지 데이터를 1000000 바이트씩 나눠서 저장\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f602e4",
   "metadata": {},
   "source": [
    "#### * 함수로 만들고 반복문으로 지정한 개수만큼 이미지를 내려받는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca669e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 파일명 : \"reshot-logo--mark-cc49363ac3f7876f854286af4266ead51a7ff9e0fa12f30677c9e758d43dd0d1.svg\".내려받기 완료!\n",
      "이미지 파일명 : \"bae96789-a5ab-4471-b54f-9686ace09e33.jpg\".내려받기 완료!\n",
      "이미지 파일명 : \"a44357c5-b1c3-41ef-9a65-7a4937b06a44.jpg\".내려받기 완료!\n",
      "이미지 파일명 : \"34fd9c70-8996-4706-a0f1-113231ed3eee.jpg\".내려받기 완료!\n",
      "이미지 파일명 : \"dbd9fa3b-238b-47b1-8e20-c05400cbe921.jpg\".내려받기 완료!\n",
      "이미지 파일명 : \"737d192f-ba38-4a71-9bb9-9d40b45d0263.jpg\".내려받기 완료!\n",
      "이미지 파일명 : \"c3c3604d-36eb-4f8a-9768-cebc0749d5a5.jpg\".내려받기 완료!\n",
      "==================================\n",
      "선택한 모든 이미지 내려받기 완료\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# URL에서 이미지 주소 추출\n",
    "def get_image_url(url):\n",
    "    html_image_url = requests.get(url).text\n",
    "    soup_image_url = BeautifulSoup(html_image_url, 'lxml')\n",
    "    image_elements = soup_image_url.select('img')\n",
    "    if(image_elements != None):\n",
    "        image_urls = []\n",
    "        for image_element in image_elements:\n",
    "            image_urls.append(image_element.get('src'))\n",
    "        return image_urls\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# 폴더를 지정해 이미지 주소에서 이미지 내려받기\n",
    "def download_image(img_folder, img_url):\n",
    "    if(img_url != None):\n",
    "        html_image=requests.get(img_url)\n",
    "        imageFile = open(os.path.join(img_folder, os.path.basename(img_url)), 'wb')\n",
    "        \n",
    "        chunk_size = 1000000\n",
    "        for chunk in html_image.iter_content(chunk_size):\n",
    "            imageFile.write(chunk)\n",
    "            imageFile.close()\n",
    "        print('이미지 파일명 : \"{0}\".내려받기 완료!'.format(os.path.basename(img_url)))\n",
    "    else:\n",
    "        print('내려받을 이미지가 없음')\n",
    "        \n",
    "# 웹사이트 주소 지정\n",
    "reshot_url = 'https://www.reshot.com/search/animal'\n",
    "\n",
    "figure_folder = \"C:/Web_Crawling/download\"\n",
    "\n",
    "reshot_image_urls = get_image_url(reshot_url) #이미지 파일의 주소 가져오기\n",
    "\n",
    "num_of_download_image = 7 # 내려받을 이미지 개수 지정\n",
    "#num_of_download_image = len(reshot_image_urls)\n",
    "\n",
    "for k in range(num_of_download_image):\n",
    "    download_image(figure_folder, reshot_image_urls[k])\n",
    "print('==================================')\n",
    "print('선택한 모든 이미지 내려받기 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27628760",
   "metadata": {},
   "source": [
    "#### * `len(reshot_image_urls)` : 이미지가 몇 개 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2b200c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_download_image = len(reshot_image_urls)\n",
    "num_of_download_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb090754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
